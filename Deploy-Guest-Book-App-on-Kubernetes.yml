The Nautilus Application development team has finished development of one of the applications and it is ready for deployment. 
It is a guestbook application that will be used to manage entries for guests/visitors. 
As per discussion with the DevOps team, they have finalized the infrastructure that will be deployed on Kubernetes cluster. 
Below you can find more details about it.

BACK-END TIER

Create a deployment named redis-master for Redis master.

a.) Replicas count should be 1.

b.) Container name should be master-redis-xfusion and it should use image redis.

c.) Request resources as CPU should be 100m and Memory should be 100Mi.

d.) Container port should be redis default port i.e 6379.

Create a service named redis-master for Redis master. Port and targetPort should be Redis default port i.e 6379.

Create another deployment named redis-slave for Redis slave.

a.) Replicas count should be 2.

b.) Container name should be slave-redis-xfusion and it should use gcr.io/google_samples/gb-redisslave:v3 image.

c.) Requests resources as CPU should be 100m and Memory should be 100Mi.

d.) Define an environment variable named GET_HOSTS_FROM and its value should be dns.

e.) Container port should be Redis default port i.e 6379.

Create another service named redis-slave. It should use Redis default port i.e 6379.

FRONT END TIER

Create a deployment named frontend.

a.) Replicas count should be 3.

b.) Container name should be php-redis-xfusion and it should use gcr.io/google-samples/gb-frontend:v4 image.

c.) Request resources as CPU should be 100m and Memory should be 100Mi.

d.) Define an environment variable named as GET_HOSTS_FROM and its value should be dns.

e.) Container port should be 80.

Create a service named frontend. Its type should be NodePort, port should be 80 and its nodePort should be 30009.

Finally, you can check the guestbook app by clicking on + button in the top left corner and Select port to view on Host 1 then enter your nodePort.

You can use any labels as per your choice.

Note: The kubectl utility on jump_host has been configured to work with the kubernetes cluster.







solution:
========

Note : for ease of naming, using short hand naming convention 
d*.yml -- deployment creation yaml file - ex: d1.yml d2.yml, d3.yml
s*.yml - service creation yaml file - ex: s1.yml, s2.yml, s3.yml

BACK-END TIER:

deployment create syntax:

 kubectl create deployment NAME --image=image -- [COMMAND] [args...] [options]

task 1 create redis-master deployment

cat d1.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: guestbook
    tier: back-end
    role: master
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: guestbook
      tier: back-end
      role: master
  template:
    metadata:
      labels:
        app: guestbook
        tier: back-end
        role: master
    spec:
      containers:
      - image: redis
        name: master-redis-xfusion
        resources:
          requests:
             cpu: "100m"
             memory: "100Mi"
        ports: 
         - containerPort: 6379
         
task 2 create service
   kubectl create service clusterip redis-master  --tcp=6379:6379 --dry-run=client \
> -o yaml > s1.yml
  
cat s1.yml

apiVersion: v1
kind: Service
metadata:
  labels:
     app: guestbook
     tier: back-end
  name: redis-master
spec:
  ports:
  - name: port
    port: 6379
    protocol: TCP
    targetPort: 6379
  selector:
    app: guestbook
    tier: back-end
  type: ClusterIP
   
task 3 create redis-slave deployment:

cat d2.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: guestbook
    tier: back-end-2
    role: slave
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: guestbook
      tier: back-end-2
      role: slave
  template:
    metadata:
      labels:
        app: guestbook
        tier: back-end-2
        role: slave
    spec:
      containers:
      - image: gcr.io/google_samples/gb-redisslave:v3
        name: slave-redis-xfusion
        resources:
          requests:
             cpu: "100m"
             memory: "100Mi"
        ports: 
         - containerPort: 6379
        env:
        - name: GET_HOSTS_FROM
          value: dns
 
 create service for 2nd deployment:
 
 cat s2.yml
 
 apiVersion: v1
kind: Service
metadata:
  labels:
     app: guestbook
     tier: back-end-2
  name: redis-slave
spec:
  ports:
  - name: port
    port: 6379
    protocol: TCP
    targetPort: 6379
  selector:
    app: guestbook
    tier: back-end-2
  type: ClusterIP
  
  
 Front-END TIER:
 create  deployment:
 
 cat d3.yml
 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: guestbook
    tier: front-end
    role: expose
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: front-end
      role: expose
  template:
    metadata:
      labels:
        app: guestbook
        tier: front-end
        role: expose
    spec:
      containers:
      - image: gcr.io/google-samples/gb-frontend:v4
        name: php-redis-xfusion
        resources:
          requests:
             cpu: "100m"
             memory: "100Mi"
        ports: 
         - containerPort: 80
        env:
        - name: GET_HOSTS_FROM
          value: dns

 create service for front end deployment: 
 cat s3.yml
   
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    app: guestbook
    tier: front-end
    role: expose
  name: frontend
spec:
  ports:
  - name: nodeport-svc
    port: 80
    protocol: TCP
    targetPort: 80
    nodePort: 30009
  selector:
    app: guestbook
    tier: front-end
    role: expose
  type: NodePort


verify:
kubectl get deployments - # 3 deployments will be listed , with number of pods for each

kubectl get svc # 3 services will be listed

get the endpoints from the service frontend


kubectl get pods # 6 pods will be listed , deployment 1 (d1.yml) = 1 pod, deployment d2.ym = 2 pods, deployment d3 = 3 pods


curl http://{endpoints of front service}

You will see guestbook page
